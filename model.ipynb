{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Phase \n",
    "\n",
    "The Modeling notebook is broken into the following parts\n",
    "- Feature Selection \n",
    "- Models \n",
    "- Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/QQQ_modified_data.csv', ).rename(columns={'Unnamed: 0': 'Date'}).drop(columns=['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first 30 rows of data to eliminate NaN values\n",
    "df = df.iloc[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies = df[['cross', 'triple cross']]\n",
    "df_with_dummies = pd.get_dummies(df_with_dummies).astype(int)\n",
    "\n",
    "df = pd.concat([df, df_with_dummies], axis=1)\n",
    "\n",
    "df = df.drop(['cross', 'triple cross'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Date', 'Future1M_movement_direction', 'Future2M_movement_direction', 'Future15d_movement_direction'])\n",
    "\n",
    "targets = df[['Future1M_movement_direction', 'Future2M_movement_direction', 'Future15d_movement_direction']].replace(-1, 0)\n",
    "\n",
    "y1M = targets['Future1M_movement_direction'].values\n",
    "y2M = targets['Future2M_movement_direction'].values\n",
    "y15D = targets['Future15d_movement_direction'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection \n",
    "- LASSO: a linear regression technique that penalizes the absolute size of the regression coefficients, effectively encouraging sparse solutions where some coefficients are exactly zero. It is commonly used for feature selection by shrinking less important features' coefficients to zero, thereby identifying the most relevant features for prediction.\n",
    "- RFE (XGBoost): feature selection technique that iteratively removes less important features based on their importance scores obtained from XGBoost. By leveraging the power of XGBoost's gradient boosting algorithm, XGBoost RFE identifies a subset of the most relevant features, improving model interpretability and potentially enhancing predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO util function\n",
    "\n",
    "def lasso_feature_selection(X, y, model_type):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    lasso = Lasso(alpha=0.1)  \n",
    "    lasso.fit(X_scaled, y)\n",
    "    \n",
    "    feature_coefficients = pd.Series(lasso.coef_, index=X.columns) \n",
    "\n",
    "    sorted_coefficients = feature_coefficients.abs().sort_values(ascending=False)\n",
    "    \n",
    "    top_10_features = sorted_coefficients.head(10)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Feature': top_10_features.index,  \n",
    "        'Coefficient': top_10_features.values,\n",
    "        'Model_Type': model_type\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST util function\n",
    "def xgboost_rfe_feature_selection(X, y, model_type):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "    \n",
    "    rfe = RFE(estimator=xgb, n_features_to_select=10)\n",
    "    rfe.fit(X_scaled, y)\n",
    "    \n",
    "    selected_features = X.columns[rfe.support_]\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Model_Type': model_type\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function - LASSO \n",
    "\n",
    "y1M_lasso_results = lasso_feature_selection(X=X, y=y1M, model_type='Lasso Regression')\n",
    "y2M_lasso_results = lasso_feature_selection(X=X, y=y2M, model_type='Lasso Regression')\n",
    "y15D_lasso_results = lasso_feature_selection(X=X, y=y15D, model_type='Lasso Regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function - rfe\n",
    "\n",
    "y1M_rfe_results = xgboost_rfe_feature_selection(X=X, y=y1M, model_type = 'XGBoost RFE')\n",
    "y2M_rfe_results = xgboost_rfe_feature_selection(X=X, y=y2M, model_type = 'XGBoost RFE')\n",
    "y15D_rfe_results = xgboost_rfe_feature_selection(X=X, y=y15D, model_type = 'XGBoost RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch together results for each respective target\n",
    "\n",
    "y1M_results = pd.concat([y1M_lasso_results, y1M_rfe_results])\n",
    "y2M_results = pd.concat([y2M_lasso_results, y2M_rfe_results])\n",
    "y15D_results = pd.concat([y15D_lasso_results, y15D_rfe_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models\n",
    "\n",
    "Types of Linear and non-linear models \n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- XGBoost\n",
    "\n",
    "Cross-validation Approach: TimeSeries Cross-Validation with 5 folds is a technique used for evaluating time series models, where the data is divided into five consecutive and non-overlapping folds. Each fold acts as a test set once while the preceding data is used for training. This approach helps assess model performance while preserving the temporal order of the data\n",
    "\n",
    "\n",
    "All models will be evaluated with the following metrics \n",
    "- Precision: Proportion of correctly classified instances (both true positives and true negatives) out of the total number of instances\n",
    "- Accuracy Metric: Proportion of true positive predictions among all positive predictions made by the model\n",
    "- Recall (True Positive Rate): Proportion of true positive predictions among all actual positive instances in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "logistic_regression = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_cross_validation(X, y, model):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5) \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X_train):\n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[test_index]  \n",
    "        y_train_cv, y_val = y_train.iloc[train_index], y_train.iloc[test_index]  \n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_pred_val)\n",
    "        precision = precision_score(y_val, y_pred_val)\n",
    "        recall = recall_score(y_val, y_pred_val)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    average_precision = np.mean(precisions)\n",
    "    average_recall = np.mean(recalls)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall'],\n",
    "        'Average_Value': [average_accuracy, average_precision, average_recall]\n",
    "    })\n",
    "\n",
    "    return results_df\n",
    "\n",
    "    average_recall = np.mean(recalls)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall'],\n",
    "        'Average_Value': [average_accuracy, average_precision, average_recall]\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_with_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my1M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogistic_regression\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[147], line 12\u001b[0m, in \u001b[0;36mevaluate_model_with_cross_validation\u001b[0;34m(X, y, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m tscv\u001b[38;5;241m.\u001b[39msplit(X_train):\n\u001b[1;32m     11\u001b[0m     X_train_cv, X_val \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_index], X_train\u001b[38;5;241m.\u001b[39miloc[test_index]  \u001b[38;5;66;03m# Use .iloc to index DataFrame\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     y_train_cv, y_val \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[test_index]  \u001b[38;5;66;03m# Use .iloc to index DataFrame\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_cv, y_train_cv)\n\u001b[1;32m     16\u001b[0m     y_pred_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = evaluate_model_with_cross_validation(X=X, y=y1M, model=logistic_regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicago",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
